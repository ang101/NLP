{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Momentum and Adam\n",
    "\n",
    "This notebook demonstrates the implementation of a three-layer neural network and compares the performance of different optimization methods: Gradient Descent (GD), Momentum, and Adam. The neural network is trained on a two-moon-shaped dataset using various optimization techniques to find the optimal parameters that minimize the cost function and improve the accuracy of the model.\n",
    "\n",
    "### Dataset\n",
    "The dataset used in this notebook is generated using the `make_moons()` function from the `sklearn.datasets` module. The dataset consists of two classes that form two moon shapes. It is a non-linearly separable dataset, making it a suitable scenario for testing different optimization methods for training a neural network.\n",
    "\n",
    "### Activation Functions\n",
    "The neural network uses two activation functions:\n",
    "\n",
    "1. **ReLU (Rectified Linear Unit)**: The ReLU activation function is used in the hidden layers of the neural network. It allows the model to handle non-linearities efficiently and avoids the vanishing gradient problem, which can occur with sigmoid activation.\n",
    "2. **Sigmoid**: The sigmoid activation function is used in the output layer to compute the final probability of the binary classification task. It maps the input to the range (0, 1), representing the probability of the input belonging to class 1.\n",
    "\n",
    "### Neural Network Architecture\n",
    "The neural network architecture is defined as a three-layer model with the following layer dimensions: [input size, 5, 2, 1]. The input size corresponds to the features of the dataset, and the output size is set to 1 for binary classification.\n",
    "\n",
    "### Optimization Methods\n",
    "\n",
    "#### 1. Gradient Descent (GD)\n",
    "Gradient Descent is a first-order optimization algorithm that updates the model's parameters in the opposite direction of the gradient of the cost function. The magnitude of the update is controlled by the learning rate. While GD is a simple and intuitive optimization method, it may suffer from slow convergence, especially for large datasets or in cases where the cost function has high curvatures.\n",
    "\n",
    "#### 2. Momentum\n",
    "Momentum is an extension of GD that introduces a moving average of the gradients to accelerate convergence. It accumulates the past gradients' information to continue moving in the same direction even when the gradients change direction frequently. This helps in faster convergence and reduces oscillations in the cost function. The momentum hyperparameter controls the influence of the past gradients.\n",
    "\n",
    "#### 3. Adam (Adaptive Moment Estimation)\n",
    "Adam is a popular optimization algorithm that combines the ideas of both Momentum and RMSprop. It uses moving averages of the past gradients and squared gradients to adapt the learning rate for each parameter. The algorithm automatically adjusts the learning rate based on the history of the gradients and their magnitudes. This adaptive learning rate makes Adam robust and efficient in practice, requiring minimal hyperparameter tuning.\n",
    "\n",
    "### Training and Evaluation\n",
    "The neural network is trained using each of the three optimization methods. For each optimization method, the model's parameters are updated iteratively over a specified number of epochs using mini-batch gradient descent. At the end of each epoch, the cost function is computed and printed to monitor the training progress. The final trained model's accuracy on the training data is also calculated and displayed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's delve into the details and theory of each optimization method along with their advantages and disadvantages.\n",
    "\n",
    "### 1. Gradient Descent (GD)\n",
    "\n",
    "**Theory**:\n",
    "Gradient Descent is a first-order optimization algorithm used to minimize the cost function of a neural network. It works by iteratively updating the model's parameters in the opposite direction of the gradient of the cost function with respect to those parameters. The gradient points in the direction of steepest ascent, so taking the opposite direction allows the algorithm to move towards the minimum of the cost function.\n",
    "\n",
    "**Algorithm**:\n",
    "1. Initialize the model's parameters randomly.\n",
    "2. Compute the gradient of the cost function with respect to each parameter.\n",
    "3. Update each parameter using the formula: `parameter = parameter - learning_rate * gradient`, where the learning_rate controls the size of the update step.\n",
    "\n",
    "**Advantages**:\n",
    "- Simple and easy to implement.\n",
    "- Can be applied to large datasets since it processes one data point at a time.\n",
    "- Can handle non-convex cost functions.\n",
    "\n",
    "**Disadvantages**:\n",
    "- Convergence can be slow, especially for large datasets or complex cost functions.\n",
    "- Sensitive to the learning rate choice; a large learning rate may lead to overshooting the minimum, while a small learning rate may result in slow convergence.\n",
    "\n",
    "### 2. Momentum\n",
    "\n",
    "**Theory**:\n",
    "Momentum is an extension of GD that aims to accelerate the convergence of the optimization process. It introduces a moving average of the past gradients to continue moving in the same direction even when the gradients change direction frequently. This helps to overcome oscillations in the cost function and speeds up convergence.\n",
    "\n",
    "**Algorithm**:\n",
    "1. Initialize the model's parameters and the velocity (initialized as zeros) for each parameter.\n",
    "2. Compute the gradient of the cost function with respect to each parameter.\n",
    "3. Update each parameter using the formula:\n",
    "   ```\n",
    "   velocity = beta * velocity + (1 - beta) * gradient\n",
    "   parameter = parameter - learning_rate * velocity\n",
    "   ```\n",
    "   where `beta` is the momentum hyperparameter.\n",
    "\n",
    "**Advantages**:\n",
    "- Accelerates convergence, especially in areas with high curvature or noisy gradients.\n",
    "- Reduces oscillations and overshooting, leading to more stable updates.\n",
    "\n",
    "**Disadvantages**:\n",
    "- Momentum may accumulate too much velocity in flat regions, making it harder to escape local minima.\n",
    "- May overshoot and oscillate when the learning rate is too large.\n",
    "\n",
    "### 3. Adam (Adaptive Moment Estimation)\n",
    "\n",
    "**Theory**:\n",
    "Adam is an adaptive learning rate optimization algorithm that combines the ideas of both Momentum and RMSprop. It uses moving averages of the past gradients and squared gradients to adapt the learning rate for each parameter. The algorithm automatically adjusts the learning rate based on the history of the gradients and their magnitudes.\n",
    "\n",
    "**Algorithm**:\n",
    "1. Initialize the model's parameters and the first and second moment estimates (initialized as zeros) for each parameter.\n",
    "2. Compute the gradient of the cost function with respect to each parameter.\n",
    "3. Update each parameter using the formula:\n",
    "   ```\n",
    "   first_moment = beta1 * first_moment + (1 - beta1) * gradient\n",
    "   second_moment = beta2 * second_moment + (1 - beta2) * gradient^2\n",
    "   first_moment_corrected = first_moment / (1 - beta1^t)\n",
    "   second_moment_corrected = second_moment / (1 - beta2^t)\n",
    "   parameter = parameter - learning_rate * first_moment_corrected / sqrt(second_moment_corrected + epsilon)\n",
    "   ```\n",
    "   where `beta1` and `beta2` are the moment hyperparameters, and `epsilon` is a small constant to prevent division by zero.\n",
    "\n",
    "**Advantages**:\n",
    "- Adaptive learning rate for each parameter, reducing the need for extensive learning rate tuning.\n",
    "- Efficient and robust in practice, suitable for a wide range of neural network architectures and cost functions.\n",
    "- Fast convergence and good generalization on various datasets.\n",
    "\n",
    "**Disadvantages**:\n",
    "- Adam may exhibit slow convergence on certain non-stationary objectives or saddle points.\n",
    "- Requires more memory to store the additional moving average parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import h5py \n",
    "import scipy.io \n",
    "import sklearn \n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat L-layer neural net with different optimizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid (x) : \n",
    "    s = 1/(1+np.exp(-x))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    s = np.maximum(0,x)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_params_and_grads(seed=1):\n",
    "    np.random.seed(seed)\n",
    "    W1 = np.random.randn(2,3)\n",
    "    b1 = np.random.randn(2,1)\n",
    "    W2 = np.random.randn(3,3)\n",
    "    b2 = np.random.randn(3,1)\n",
    "\n",
    "    dW1 = np.random.randn(2,3)\n",
    "    db1 = np.random.randn(2,1)\n",
    "    dW2 = np.random.randn(3,3)\n",
    "    db2 = np.random.randn(3,1)\n",
    "    \n",
    "    return W1, b1, W2, b2, dW1, db1, dW2, db2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims) : \n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len (layer_dims)\n",
    "\n",
    "    for i in range (1 , L) : \n",
    "        parameters['W' + str (i)] = np.random.rand ( layer_dims[i] ,layer_dims[i-1]) * np.sqrt (2/layer_dims[i-1])\n",
    "        parameters['b' + str(i)] = np.zeros(shape=(layer_dims[i] ,1 ))\n",
    "\n",
    "    return parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost (a3 , y) : \n",
    "    m = max (np.shape(y))\n",
    "    cost = 1./m * np.sum(np.multiply (-np.log(a3),y) + np.multiply(-np.log(1 - a3), 1 - y))\n",
    "    return cost \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X , parameters) : \n",
    "        \n",
    "    # retrieve parameters\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    W3 = parameters[\"W3\"]\n",
    "    b3 = parameters[\"b3\"]\n",
    "    \n",
    "    # LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID\n",
    "    z1 = np.dot(W1, X) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(W2, a1) + b2\n",
    "    a2 = relu(z2)\n",
    "    z3 = np.dot(W3, a2) + b3\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    cache = (z1, a1, W1, b1, z2, a2, W2, b2, z3, a3, W3, b3)\n",
    "    \n",
    "    return a3, cache "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, Y, cache):\n",
    "    m = X.shape[1]\n",
    "    (z1, a1, W1, b1, z2, a2, W2, b2, z3, a3, W3, b3) = cache\n",
    "    \n",
    "    dz3 = 1./m * (a3 - Y)\n",
    "    dW3 = np.dot(dz3, a2.T)\n",
    "    db3 = np.sum(dz3, axis=1, keepdims = True)\n",
    "    \n",
    "    da2 = np.dot(W3.T, dz3)\n",
    "    dz2 = np.multiply(da2, np.int64(a2 > 0))\n",
    "    dW2 = np.dot(dz2, a1.T)\n",
    "    db2 = np.sum(dz2, axis=1, keepdims = True)\n",
    "    \n",
    "    da1 = np.dot(W2.T, dz2)\n",
    "    dz1 = np.multiply(da1, np.int64(a1 > 0))\n",
    "    dW1 = np.dot(dz1, X.T)\n",
    "    db1 = np.sum(dz1, axis=1, keepdims = True)\n",
    "    \n",
    "    gradients = {\"dz3\": dz3, \"dW3\": dW3, \"db3\": db3,\n",
    "                 \"da2\": da2, \"dz2\": dz2, \"dW2\": dW2, \"db2\": db2,\n",
    "                 \"da1\": da1, \"dz1\": dz1, \"dW1\": dW1, \"db1\": db1}\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    a3, caches = forward_propagation(X, parameters)\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, a3.shape[1]):\n",
    "        if a3[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "\n",
    "    print(\"Accuracy: \"  + str(np.mean((p[0,:] == y[0,:]))))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dec(parameters, X):\n",
    "    \"\"\"\n",
    "    Used for plotting decision boundary.\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    X -- input data of size (m, K)\n",
    "    \n",
    "    Returns\n",
    "    predictions -- vector of predictions of our model (red: 0 / blue: 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Predict using forward propagation and a classification threshold of 0.5\n",
    "    a3, cache = forward_propagation(X, parameters)\n",
    "    predictions = (a3 > 0.5)\n",
    "    return predictions\n",
    "\n",
    "def load_dataset():\n",
    "    np.random.seed(3)\n",
    "    train_X, train_Y = sklearn.datasets.make_moons(n_samples=300, noise=.2) #300 #0.2 \n",
    "    # Visualize the data\n",
    "    plt.scatter(train_X[:, 0], train_X[:, 1], c=train_Y, s=40, cmap=plt.cm.Spectral);\n",
    "    train_X = train_X.T\n",
    "    train_Y = train_Y.reshape((1, train_Y.shape[0]))\n",
    "    \n",
    "    return train_X, train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_parameters_with_gd(parameters, grads, learning_rate):\n",
    "   \n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "\n",
    "    # Update rule for each parameter\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((1,m))\n",
    "\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:,k * mini_batch_size:(k + 1) * mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:,k * mini_batch_size:(k + 1) * mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        end = m - mini_batch_size * math.floor(m / mini_batch_size)\n",
    "        mini_batch_X = shuffled_X[:,num_complete_minibatches * mini_batch_size:]\n",
    "        mini_batch_Y = shuffled_Y[:,num_complete_minibatches * mini_batch_size:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batches = random_mini_batches(train_X, train_Y, mini_batch_size = 128 )\n",
    "print (\"shape of the X_train is \" , np.shape (train_X))\n",
    "print(\"shape of the 1st mini_batch_X: \" + str(mini_batches[0][0].shape))\n",
    "print(\"shape of the 2nd mini_batch_X: \" + str(mini_batches[1][0].shape))\n",
    "print(\"shape of the 3rd mini_batch_X: \" + str(mini_batches[2][0].shape))\n",
    "print(\"shape of the 1st mini_batch_Y: \" + str(mini_batches[0][1].shape))\n",
    "print(\"shape of the 2nd mini_batch_Y: \" + str(mini_batches[1][1].shape)) \n",
    "print(\"shape of the 3rd mini_batch_Y: \" + str(mini_batches[2][1].shape))\n",
    "print(\"mini batch sanity check: \" + str(mini_batches[0][0][0][0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_velocity(parameters):\n",
    "  \n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    v = {}\n",
    "    \n",
    "    # Initialize velocity\n",
    "    for l in range(L):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        v[\"dW\" + str(l + 1)] = np.zeros_like(parameters[\"W\" + str(l+1)])\n",
    "        v[\"db\" + str(l + 1)] = np.zeros_like(parameters[\"b\" + str(l+1)])\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_parameters_with_momentum(parameters, grads, v, beta, learning_rate) :\n",
    "\n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    \n",
    "    # Momentum update for each parameter\n",
    "    for l in range(L):\n",
    "        \n",
    "        # compute velocities\n",
    "        v[\"dW\" + str(l + 1)] = beta * v[\"dW\" + str(l + 1)] + (1 - beta) * grads['dW' + str(l + 1)]\n",
    "        v[\"db\" + str(l + 1)] = beta * v[\"db\" + str(l + 1)] + (1 - beta) * grads['db' + str(l + 1)]\n",
    "        # update parameters\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * v[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * v[\"db\" + str(l + 1)]\n",
    "        \n",
    "    return parameters, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # ADAM Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_adam(parameters) :\n",
    "    \"\"\"\n",
    "    Initializes v and s as two python dictionaries with:\n",
    "                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n",
    "                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters.\n",
    "                    parameters[\"W\" + str(l)] = Wl\n",
    "                    parameters[\"b\" + str(l)] = bl\n",
    "    \n",
    "    Returns: \n",
    "    v -- python dictionary that will contain the exponentially weighted average of the gradient.\n",
    "                    v[\"dW\" + str(l)] = ...\n",
    "                    v[\"db\" + str(l)] = ...\n",
    "    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.\n",
    "                    s[\"dW\" + str(l)] = ...\n",
    "                    s[\"db\" + str(l)] = ...\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    # Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\n",
    "    for l in range(L):\n",
    "    ### START CODE HERE ### (approx. 4 lines)\n",
    "        v[\"dW\" + str(l + 1)] = np.zeros_like(parameters[\"W\" + str(l + 1)])\n",
    "        v[\"db\" + str(l + 1)] = np.zeros_like(parameters[\"b\" + str(l + 1)])\n",
    "\n",
    "        s[\"dW\" + str(l+1)] = np.zeros_like(parameters[\"W\" + str(l + 1)])\n",
    "        s[\"db\" + str(l+1)] = np.zeros_like(parameters[\"b\" + str(l + 1)])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate=0.01,\n",
    "                                beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "    \n",
    "    L = len(parameters) // 2                 # number of layers in the neural networks\n",
    "    v_corrected = {}                         # Initializing first moment estimate, python dictionary\n",
    "    s_corrected = {}                         # Initializing second moment estimate, python dictionary\n",
    "    \n",
    "    # Perform Adam update on all parameters\n",
    "    for l in range(L):\n",
    "        # Moving average of the gradients. Inputs: \"v, grads, beta1\". Output: \"v\".\n",
    "        v[\"dW\" + str(l + 1)] = beta1 * v[\"dW\" + str(l + 1)] + (1 - beta1) * grads['dW' + str(l + 1)]\n",
    "        v[\"db\" + str(l + 1)] = beta1 * v[\"db\" + str(l + 1)] + (1 - beta1) * grads['db' + str(l + 1)]\n",
    "\n",
    "        # Compute bias-corrected first moment estimate. Inputs: \"v, beta1, t\". Output: \"v_corrected\".\n",
    "        v_corrected[\"dW\" + str(l + 1)] = v[\"dW\" + str(l + 1)] / (1 - np.power(beta1, t))\n",
    "        v_corrected[\"db\" + str(l + 1)] = v[\"db\" + str(l + 1)] / (1 - np.power(beta1, t))\n",
    "\n",
    "        # Moving average of the squared gradients. Inputs: \"s, grads, beta2\". Output: \"s\".\n",
    "        s[\"dW\" + str(l + 1)] = beta2 * s[\"dW\" + str(l + 1)] + (1 - beta2) * np.power(grads['dW' + str(l + 1)], 2)\n",
    "        s[\"db\" + str(l + 1)] = beta2 * s[\"db\" + str(l + 1)] + (1 - beta2) * np.power(grads['db' + str(l + 1)], 2)\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate. Inputs: \"s, beta2, t\". Output: \"s_corrected\".\n",
    "        s_corrected[\"dW\" + str(l + 1)] = s[\"dW\" + str(l + 1)] / (1 - np.power(beta2, t))\n",
    "        s_corrected[\"db\" + str(l + 1)] = s[\"db\" + str(l + 1)] / (1 - np.power(beta2, t))\n",
    "\n",
    "        # Update parameters. Inputs: \"parameters, learning_rate, v_corrected, s_corrected, epsilon\". Output: \"parameters\".\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * v_corrected[\"dW\" + str(l + 1)] / np.sqrt(s[\"dW\" + str(l + 1)] + epsilon)\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * v_corrected[\"db\" + str(l + 1)] / np.sqrt(s[\"db\" + str(l + 1)] + epsilon)\n",
    "\n",
    "    return parameters, v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims, optimizer, learning_rate=0.0007, mini_batch_size=64, beta=0.9,\n",
    "          beta1=0.9, beta2=0.999, epsilon=1e-8, num_epochs=10000, print_cost=True):\n",
    "\n",
    "    L = len(layers_dims)             # number of layers in the neural networks\n",
    "    costs = []                       # to keep track of the cost\n",
    "    t = 0                            # initializing the counter required for Adam update\n",
    "    seed = 10                        # For grading purposes, so that your \"random\" minibatches are the same as ours\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    if optimizer == \"gd\":\n",
    "        pass # no initialization required for gradient descent\n",
    "    elif optimizer == \"momentum\":\n",
    "        v = initialize_velocity(parameters)\n",
    "    elif optimizer == \"adam\":\n",
    "        v, s = initialize_adam(parameters)\n",
    "    \n",
    "    # Optimization loop\n",
    "    for i in range(num_epochs):\n",
    "        \n",
    "        # Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch\n",
    "        seed = seed + 1\n",
    "        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)\n",
    "\n",
    "        for minibatch in minibatches:\n",
    "\n",
    "            # Select a minibatch\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "            # Forward propagation\n",
    "            a3, caches = forward_propagation(minibatch_X, parameters)\n",
    "\n",
    "            # Compute cost\n",
    "            cost = compute_cost(a3, minibatch_Y)\n",
    "\n",
    "            # Backward propagation\n",
    "            grads = backward_propagation(minibatch_X, minibatch_Y, caches)\n",
    "\n",
    "            # Update parameters\n",
    "            if optimizer == \"gd\":\n",
    "                parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n",
    "            elif optimizer == \"momentum\":\n",
    "                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)\n",
    "            elif optimizer == \"adam\":\n",
    "                t = t + 1 # Adam counter\n",
    "                parameters, v, s = update_parameters_with_adam(parameters, grads, v, s,\n",
    "                                                               t, learning_rate, beta1, beta2,  epsilon)\n",
    "        \n",
    "        # Print the cost every 1000 epoch\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print(\"Cost after epoch %i: %f\" % (i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "                \n",
    "    # plot the cost\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epochs (per 100)')\n",
    "    plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3-layer model\n",
    "layers_dims = [train_X.shape[0], 5, 2, 1]\n",
    "parameters = model(train_X, train_Y, layers_dims, optimizer=\"gd\")\n",
    "\n",
    "# Predict\n",
    "predictions = predict(train_X, train_Y, parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train 3-layer model\n",
    "layers_dims = [train_X.shape[0], 5, 2, 1]\n",
    "parameters = model(train_X, train_Y, layers_dims, beta=0.9, optimizer=\"momentum\")\n",
    "\n",
    "# Predict\n",
    "predictions = predict(train_X, train_Y, parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3-layer model\n",
    "layers_dims = [train_X.shape[0], 5, 2, 1]\n",
    "parameters = model(train_X, train_Y, layers_dims, optimizer=\"adam\")\n",
    "\n",
    "# Predict\n",
    "predictions = predict(train_X, train_Y, parameters)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The notebook provides an insight into the effectiveness of different optimization methods in training neural networks. By comparing the performance of GD, Momentum, and Adam, we can gain a better understanding of how these algorithms handle the optimization process and improve the neural network's convergence and accuracy on non-linear datasets like the two-moon-shaped dataset used here.\n",
    "\n",
    "Each optimization method has its strengths and weaknesses, and the choice of the optimization algorithm may depend on the specific problem, dataset, and neural network architecture. While Gradient Descent is a simple baseline algorithm, Momentum and Adam often offer faster convergence and more stable updates in practice. However, Adam may require more memory due to the additional moving average parameters.\n",
    "\n",
    "It is recommended to experiment with different optimization methods and hyperparameter values to find the optimal combination that yields the best convergence and accuracy for a given neural network task. Additionally, other optimization techniques, such as Adagrad, RMSprop, and Nesterov Accelerated Gradient (NAG), are also widely used in practice and may be worth exploring for specific scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
