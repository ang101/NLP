{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "from helper import build_LSTM_model, compile_LSTM_model, train_LSTM_model, create_input_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)\n",
    "train_data = dataset['train'].map(lambda x, y: x)\n",
    "test_data = dataset['test'].map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 19:38:19.475321: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-11-21 19:38:19.504921: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "#Limit only first 650 rows in train_data and 150 in test_data\n",
    "\n",
    "train_texts = list(train_data.take(1000))\n",
    "test_texts = list(test_data.take(250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.numpy().decode('utf-8').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bigrams(text):\n",
    "    words = tokenize(text)\n",
    "    bigrams = [(words[i], words[i + 1]) for i in range(len(words) - 1)]\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bigrams = [bigram for text in train_texts for bigram in extract_bigrams(text)]\n",
    "test_bigrams = [bigram for text in test_texts for bigram in extract_bigrams(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = [w for bigram in train_bigrams for w in bigram]\n",
    "test_words = [w for bigram in test_bigrams for w in bigram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(train_words))\n",
    "vocab_size = len(vocab)\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "word_to_idx[\"<UNK>\"] = vocab_size  # Unknown token\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Words to Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = [word_to_idx.get(word, word_to_idx[\"<UNK>\"]) for word in train_words]\n",
    "test_sequences = [word_to_idx.get(word, word_to_idx[\"<UNK>\"]) for word in test_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input-output sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_input_output(train_sequences)\n",
    "X_test, y_test = create_input_output(test_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building, compiling, and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7032/7032 [==============================] - 118s 17ms/step - loss: 6.5586 - accuracy: 0.2419 - val_loss: 6.0650 - val_accuracy: 0.3297\n",
      "Epoch 2/3\n",
      "7032/7032 [==============================] - 118s 17ms/step - loss: 5.2669 - accuracy: 0.3615 - val_loss: 5.8146 - val_accuracy: 0.3766\n",
      "Epoch 3/3\n",
      "7032/7032 [==============================] - 116s 16ms/step - loss: 4.6801 - accuracy: 0.4048 - val_loss: 5.7156 - val_accuracy: 0.3968\n"
     ]
    }
   ],
   "source": [
    "model = build_LSTM_model(vocab_size, X_train.shape[1])\n",
    "compile_LSTM_model(model)\n",
    "with tf.device('/GPU:0'):\n",
    "    train_LSTM_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate cross-entropy loss and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3202/3202 [==============================] - 8s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "def calculate_perplexity(model, X, y):\n",
    "    \"\"\"Calculate perplexity of the model.\"\"\"\n",
    "    with tf.device('/GPU:0'):\n",
    "        predictions = model.predict(X)\n",
    "        log_prob_sum = 0\n",
    "        N = len(y)\n",
    "        \n",
    "        for i in range(N):\n",
    "            prob = predictions[i, y[i]]\n",
    "            log_prob_sum += np.log(prob + 1e-10)  # Smoothing to avoid log(0)\n",
    "        \n",
    "        perplexity = np.exp(-log_prob_sum / N)\n",
    "        return perplexity\n",
    "\n",
    "perplexity = calculate_perplexity(model, X_test, y_test)\n",
    "print(f'Perplexity: {perplexity}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
