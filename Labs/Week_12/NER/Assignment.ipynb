{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition using Bidirectional LSTM\n",
    "\n",
    "**Bidirectional LSTM (BiLSTM)** is an extension of the traditional LSTM, which is a type of recurrent neural network (RNN) designed to handle sequential data effectively. While standard LSTMs process input data in one direction (typically from past to future), BiLSTMs process data in both forward and backward directions. This dual processing allows BiLSTMs to capture information from both past and future contexts of a sequence, making them particularly powerful for tasks that rely on context.\n",
    "\n",
    "Key Features:\n",
    "Forward and Backward Layers: A BiLSTM has two LSTM layers:\n",
    "Forward Layer: Processes the sequence from the beginning to the end.\n",
    "Backward Layer: Processes the sequence from the end to the beginning.\n",
    "Concatenated Outputs: The outputs of the forward and backward layers are typically concatenated at each time step, providing a richer representation of the input sequence.\n",
    "\n",
    "\n",
    "Official Keras documentation for Bi-directional LSTM: [Bi-drectional LSTM](https://keras.io/api/layers/recurrent_layers/bidirectional/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, TimeDistributed, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from seqeval.metrics import classification_report as seqeval_report\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report\n",
    "from tests import test_data, test_model, test_validation_accuracy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filepath):\n",
    "    data = # TODO:Load the dataset and fill missing values\n",
    "    test_data(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating mappings and sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter:\n",
    "    def __init__(self, data):\n",
    "        self.sentences = self.aggregate_sentences(data)\n",
    "\n",
    "    def aggregate_sentences(self, data):\n",
    "        agg_func = # TODO: Aggregate sentences\n",
    "        return data.groupby(\"Sentence #\").apply(agg_func).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mappings(data):\n",
    "    #TODO: Create mappings for words and tags\n",
    "    # CODE STARTS HERE\n",
    "\n",
    "    #CODE ENDS HERE\n",
    "    return words, tags, word2idx, tag2idx, idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(sentences, word2idx, tag2idx, max_len):\n",
    "    # TODO: Prepare data for training by padding sequences for words and tags\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO: Build Model\n",
    "'''\n",
    "Embedding dimension 128\n",
    "128 lstm units\n",
    "dropout rate of 0.4\n",
    "batch size 64\n",
    "3 epochs\n",
    "learning rate of 0.002\n",
    "'''\n",
    "EMBEDDING_DIM = \n",
    "LSTM_UNITS = \n",
    "DROPOUT_RATE = \n",
    "BATCH_SIZE = \n",
    "EPOCHS =\n",
    "LEARNING_RATE = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(input_dim, output_dim, input_length, lstm_units, dropout_rate):\n",
    "    \"\"\"Build the BiLSTM model.\"\"\"\n",
    "    input_layer = # TODO: create an input layer of length input \n",
    "    embedding = # TODO: create an embedding layer for input layer of input dimension, output dimension, input length \n",
    "    dropout1 = # TODO: create a dropout layer with specified dropout rate for embedding layer\n",
    "\n",
    "    lstm1 = # # TODO: Apply BIDIRECTIONAL LSTM on the output of 1st dropout layer\n",
    "    dropout2 = # TODO: Apply dropout to 1st LSTM \n",
    "    lstm2 = # TODO: Processes the output of the first LSTM layer with half the neurons for further refinement\n",
    "    dropout3 = # TODO: Apply dropout to 2nd LSTM \n",
    "\n",
    "    output = TimeDistributed(Dense(len(tag2idx), activation=\"softmax\"))(dropout3)\n",
    "\n",
    "    model = Model(input_layer, output)\n",
    "    \n",
    "    test_model(model, input_dim, EMBEDDING_DIM, input_length, LSTM_UNITS, len(tag2idx))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, batch_size, epochs, learning_rate):\n",
    "    \"\"\"Compile and train the model.\"\"\"\n",
    "    optimizer = # TODO: Initialize Nadam optimizer with learning_rate parameter \n",
    "\n",
    "    # TODO: Compile model with categorical crossentropy loss and accuracy as metrics\n",
    "\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1, min_lr=1e-5)\n",
    "\n",
    "    history = # TODO: Train the model by passing training data, specifying batch size, epochs, 0.1 as validation split, lr_scheduler as callback\n",
    "    test_validation_accuracy(history)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, idx2tag):\n",
    "    \"\"\"Evaluate the model and generate predictions.\"\"\"\n",
    "    y_pred = # TODO: Predict using the model\n",
    "    y_pred_tags = # TODO: select the index of the maximum probability class from predicted value\n",
    "    y_true_tags = # TODO: select the index of the maximum probability class from test value\n",
    "\n",
    "    y_pred_flat = [idx2tag[i] for row in y_pred_tags for i in row]\n",
    "    y_true_flat = [idx2tag[i] for row in y_true_tags for i in row]\n",
    "\n",
    "    report = # TODO: Create classification report using flattened true and predicted values\n",
    "    return report, y_pred_tags, y_true_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_tags(sentence_idx, y_pred_tags, y_true_tags, idx2tag, X_test, idx2word):\n",
    "    words = # TODO: Retrieves the words in the sentence at sentence_idx from X_test using idx2word excluding any padding\n",
    "\n",
    "    true_tags = # TODO: Retrieves the true tags for the sentence at sentence_idx from y_true_tags using idx2tag. exclude \"O\" tag\n",
    "    \n",
    "    pred_tags = # TODO: Similar to the above, but for the predicted tags (y_pred_tags)\n",
    "\n",
    "    return words, true_tags, pred_tags\n",
    "\n",
    "def display_sample_predictions(X_test, y_pred_tags, y_true_tags, idx2tag, word2idx):\n",
    "    \"\"\"Display random sample predictions.\"\"\"\n",
    "    idx2word = {i: w for w, i in word2idx.items()}\n",
    "    num_examples = 5\n",
    "    print(\"\\nSample Predictions vs Actual Tags:\\n\")\n",
    "\n",
    "    for _ in range(num_examples):\n",
    "        sentence_idx = random.randint(0, len(X_test) - 1)\n",
    "\n",
    "        words, true_tags, pred_tags = # TODO: Call decode_tags function\n",
    "        \n",
    "        print(\"Sentence: \", \" \".join(words))\n",
    "        print(\"Actual Tags: \", \" \".join(true_tags))\n",
    "        print(\"Predicted Tags: \", \" \".join(pred_tags))\n",
    "        print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "filepath = \"ner_dataset.csv\"\n",
    "data = # TODO: Load data using the filepath\n",
    "\n",
    "# Prepare Sentences\n",
    "getter = # TODO: Call SentenceGetter function\n",
    "sentences = # TODO: Get sentences from getter\n",
    "\n",
    "words, tags, word2idx, tag2idx, idx2tag = # TODO: Create mappings\n",
    "\n",
    "# Prepare Data\n",
    "MAX_LEN = 50\n",
    "X, y = # TODO: Prepare sequences\n",
    "\n",
    "X_train, X_test, y_train, y_test = # TODO: Create train test split with test size as 0.1 and random state 42\n",
    "\n",
    "model = # TODO: Build model with below parameters or by passing the below parameters:\n",
    "'''\n",
    "Embedding dimension 128\n",
    "128 lstm units\n",
    "dropout rate of 0.4\n",
    "batch size 64\n",
    "3 epochs\n",
    "learning rate of 0.002\n",
    "'''\n",
    "model.summary()\n",
    "\n",
    "# TODO: Train the model\n",
    "\n",
    "# Evaluate Model\n",
    "report, y_pred_tags, y_true_tags = # TODO: Call evaluation method\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# TODO: Display Sample Predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
