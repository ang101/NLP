{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7efda927",
   "metadata": {},
   "source": [
    "# Neural Networks Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f444ee4",
   "metadata": {},
   "source": [
    "Welcome! You will build a Neural Network to recognize handwritten digits. \n",
    "This assignment will step you through how to do this with a Neural Network mindset, and will also hone your intuitions about deep learning.\n",
    "\n",
    "#### Instructions\n",
    "- Do not modify any of the codes.\n",
    "- Only write code when prompted. For example in some sections you will find the following,\n",
    "```\n",
    "# YOUR CODE GOES HERE\n",
    "# YOUR CODE ENDS HERE\n",
    "# TODO\n",
    "```\n",
    "\n",
    "Only modify those sections of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e2b04",
   "metadata": {},
   "source": [
    "You will learn to:\n",
    "\n",
    "- Build the general architecture of a neural network, including:\n",
    "    - Initializing parameters\n",
    "    - Calculating the cost function and its gradient\n",
    "    - Using an optimization algorithm (gradient descent)\n",
    "- Gather all three functions above into a main model function, in the right order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e24fd39",
   "metadata": {},
   "source": [
    "## Imports and loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f59d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from helpers import *\n",
    "from tests import *\n",
    "\n",
    "# Import dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load dataset into training and testing sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca98034",
   "metadata": {},
   "source": [
    "## Visualizing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff68cd93",
   "metadata": {},
   "source": [
    "### What are the number of images in training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e3858a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85755339",
   "metadata": {},
   "source": [
    "#### Expected Output:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a256809a",
   "metadata": {},
   "source": [
    "60000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b564f9",
   "metadata": {},
   "source": [
    "### What are the number of images in test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0a3ed3",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da39d8",
   "metadata": {},
   "source": [
    "### How many labels are there in the dataset and what's the count of images in each label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb9710a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images belonging to 0 is 0\n",
      "Number of images belonging to 1 is 0\n",
      "Number of images belonging to 2 is 0\n",
      "Number of images belonging to 3 is 0\n",
      "Number of images belonging to 4 is 0\n",
      "Number of images belonging to 5 is 0\n",
      "Number of images belonging to 6 is 0\n",
      "Number of images belonging to 7 is 0\n",
      "Number of images belonging to 8 is 0\n",
      "Number of images belonging to 9 is 0\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "for cls in range(num_classes):\n",
    "    count = 0\n",
    "  # YOUR CODE GOES HERE\n",
    "\n",
    "  # YOUR CODE ENDS HERE\n",
    "    print(\"Number of images belonging to {} is {}\".format(cls, count))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d217bad",
   "metadata": {},
   "source": [
    "#### Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee8dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize a grid of images from the training set\n",
    "display_samples(X_train, y_train, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d2959f",
   "metadata": {},
   "source": [
    "### Preprocessing the dataset\n",
    "\n",
    "The pixel values of the images range from 0 through 255. Scale these values to a range of 0 to 1 by dividing the values by 255.0. This also converts the sample data from integers to floating-point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b485ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    \"\"\"Preprocesses the training and testing data for a machine learning model.\n",
    "\n",
    "    Args:\n",
    "      X_train: Training dataset features.\n",
    "      X_test: Testing dataset features.\n",
    "      y_train: Training dataset labels.\n",
    "      y_test: Testing dataset labels.\n",
    "\n",
    "    Returns:\n",
    "      X_train: Preprocessed training dataset features.\n",
    "      X_test: Preprocessed testing dataset features.\n",
    "      y_train: Preprocessed training dataset labels.\n",
    "      y_test: Preprocessed testing dataset labels.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Data Normalization\n",
    "    # YOUR CODE GOES HERE\n",
    "    \n",
    "    X_train =\n",
    "    X_test =\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    preprocessing_tests(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695131a",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "Here, you will be building a feedforward neural network with one hidden layer with 10 neurons in the output layer. Let the activation function be ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd70402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Import necessary modules\n",
    "\n",
    "def build_model(input_shape, num_classes, activation_function):\n",
    "    \"\"\"Builds a feedforward neural network model.\n",
    "\n",
    "    Args:\n",
    "        input_shape: Tuple specifying the input shape.\n",
    "        num_classes: Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # 1. Input Layer\n",
    "        \n",
    "    # Add a hidden layers with 'relu' activation function and 128 neurons\n",
    "    # Ensure that the final layer has 10 neurons since we have 10 labels in output\n",
    "\n",
    "        \n",
    "    # YOUR CODE GOES HERE\n",
    "        \n",
    "    # YOUR CODE ENDS HERE\n",
    "])\n",
    "    test_model_structure(model)\n",
    "    return model\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c705e262",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45e06741",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)  # for reproducibility\n",
    "tf.random.set_seed(43)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff508de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO\n",
    "\n",
    "def compile_model(model):\n",
    "    \"\"\"Compiles the given model.\n",
    "\n",
    "    Args:\n",
    "      model(tf.keras.Model): The model to be compiled.\n",
    "\n",
    "    Returns:\n",
    "      None\n",
    "    \"\"\"\n",
    "    #Compile the model such that add a categorical cross entropy loss function,\n",
    "    # adam optimizer and measure the performance using 'Accuracy' metric.\n",
    "\n",
    "    # YOUR CODE GOES HERE\n",
    "\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    test_model_compilation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bfe7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, model, epochs, val_split, batch_sz):\n",
    "    \"\"\"Trains the model using the provided training data.\n",
    "\n",
    "    Args:\n",
    "        x_train: Training dataset features.\n",
    "        y_train: Training dataset labels.\n",
    "        model (tf.keras.Model): The compiled neural network model.\n",
    "        epochs (int, optional): Number of epochs to train the model. Defaults to 10.\n",
    "        val_split (float, optional): Fraction of the training data to be used as validation data. Defaults to 0.2.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.callbacks.History: The training history object.\n",
    "    \"\"\"\n",
    "    device = detect_and_set_device()\n",
    "    with tf.device('/' + device + ':0'):\n",
    "\n",
    "        history = model.fit(\n",
    "            x_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_sz,\n",
    "            validation_split=val_split,\n",
    "        )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e734031",
   "metadata": {},
   "source": [
    "## Training and evaluation\n",
    "\n",
    "Here, you shall be building a pipeline from preprocessing the dataset to training on it.\n",
    "Complete all the TODOs in the following section.\n",
    "Also, you need to **achieve atleast 50% on the validation accuracy to pass this test.**"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "id": "c4d1ff55",
   "metadata": {},
   "source": [
    "### Calculate loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, x_batch, y_batch):\n",
    "    \"\"\"\n",
    "    Calculates the loss for a given batch of inputs and labels.\n",
    "    \"\"\"\n",
    "    # Forward pass to get predictions\n",
    "    y_pred = model(x_batch, training=False)\n",
    "    \n",
    "    # Calculate CATEGORICAL CROSS ENTROPY loss by looking at keras losses class. \n",
    "    loss = # YOUR CODE GOES HERE\n",
    "    return loss.numpy()\n"
   ]
  },
  {
=======
>>>>>>> 281323aec005e9c82281f5a69c2b467e7cd4c1f4
   "cell_type": "code",
   "execution_count": null,
   "id": "9033205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "def main(epochs, val_split, batch_sz):\n",
    "    \"\"\"Main function to run the training pipeline.\n",
    "\n",
    "    Args:\n",
    "        epochs(int, optional): Number of epochs to train the model.\n",
    "        val_split: Fraction of the training data to be used as validation data.\n",
    "        batch_sz: Batch size for training.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    # (TODO)Preprocess the data\n",
    "    x_train, x_test, y_train, y_test = # YOUR CODE GOES HERE\n",
    "\n",
    "    activation_function = 'relu'\n",
    "    # (TODO)Build Model\n",
    "    model =  # YOUR CODE GOES HERE\n",
    "\n",
    "    # (TODO)Compile model\n",
    "\n",
    "    # Train model\n",
    "    history = train_model(x_train, y_train, model, epochs=epochs, val_split=val_split, batch_sz=batch_sz)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    print('Test accuracy:', test_acc)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Plots\n",
    "    plot_metrics(history)\n",
    "    plot_predictions(X_test, y_true, y_pred, num_samples=16)\n",
    "\n",
<<<<<<< HEAD
    "\n",
    "    # (TODO)Calcultae loss on a batch of first 16 samples\n",
    "    loss_on_batch = # YOUR CODE\n",
    "    print(f'Loss on batch: {loss_on_batch}')\n",
    "    \n",
    "    test_model_accuracy(history=history)\n",
    "    test_check_loss_function(model)\n",
=======
    "    test_model_accuracy(history=history)\n",
>>>>>>> 281323aec005e9c82281f5a69c2b467e7cd4c1f4
    "\n",
    "    if __name__ == \"__main__\":\n",
    "\n",
    "        # (TODO) Feel free to adjust the parameters\n",
    "        main(epochs=5, val_split=0.2, batch_sz=32)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba0b246",
   "metadata": {},
   "source": [
    "### TanH activation function\n",
    "We'll train the same model but with a different activation function to see how it impacts the output results. Comment on how activation function changes the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "def main(epochs, val_split, batch_sz):\n",
    "    \"\"\"Main function to run the training pipeline.\n",
    "\n",
    "    Args:\n",
    "        epochs(int, optional): Number of epochs to train the model.\n",
    "        val_split: Fraction of the training data to be used as validation data.\n",
    "        batch_sz: Batch size for training.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    # (TODO)Preprocess the data\n",
    "    x_train, x_test, y_train, y_test = # YOUR CODE GOES HERE\n",
    "\n",
    "    activation_function = 'tanh'\n",
    "    # (TODO)Build Model\n",
    "    model =  # YOUR CODE GOES HERE\n",
    "\n",
    "    # (TODO)Compile model\n",
    "\n",
    "    # Train model\n",
    "    history = train_model(x_train, y_train, model, epochs=epochs, val_split=val_split, batch_sz=batch_sz)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    print('Test accuracy:', test_acc)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Plots\n",
    "    plot_metrics(history)\n",
    "    plot_predictions(X_test, y_true, y_pred, num_samples=16)\n",
    "\n",
    "    test_model_accuracy(history=history)\n",
<<<<<<< HEAD
    "    \n",
=======
>>>>>>> 281323aec005e9c82281f5a69c2b467e7cd4c1f4
    "\n",
    "    if __name__ == \"__main__\":\n",
    "\n",
    "        # (TODO) Feel free to adjust the parameters\n",
    "        main(epochs=5, val_split=0.2, batch_sz=32)\n",
    "     "
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##COMMENT GOES HERE"
   ]
  },
  {
=======
>>>>>>> 281323aec005e9c82281f5a69c2b467e7cd4c1f4
   "cell_type": "markdown",
   "id": "f7980165",
   "metadata": {},
   "source": [
    "## Improvement Startegies\n",
    "\n",
    "Consider the following strategies to help improve the accuracy of the above model.\n",
    "\n",
    "- Increase the number of epochs: The model might need more training iterations to learn the patterns in the data effectively.\n",
    "- Add more FFN layers: Stacking multiple FFN layers can help the model capture more complex dependencies.\n",
    "- Adjust the learning rate: Fine-tuning the learning rate can impact the model's convergence speed and performance.\n",
    "- Try different Optimizers: Explore various optimization algorithms (e.g., SGD, RMSprop). Replace Adam in the compile_model function with another optimizer from keras.optimizers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
